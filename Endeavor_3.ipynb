{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is a zip\n",
      "not a claim\n",
      "afile is empty\n",
      "bpfile is empty\n"
     ]
    }
   ],
   "source": [
    "import zipfile as z\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "afile = [] \n",
    "bifile = []\n",
    "bpfile = []\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%b_%d_%Y_%H_%M\")\n",
    "log = {\"file_name\" : [],\"file_release\":[], \"Num_claims\": [], \"Num_835\": [], \"Num_837\": [], \"Num_837p\":[], \"Num_837i\":[]}\n",
    "\n",
    "def log_file(file, item):\n",
    "    log['file_name'].append(item)\n",
    "    log['Num_claims'].append(file.count('ISA*'))\n",
    "    log['Num_835'].append(file.count('~ST*835'))\n",
    "    log['Num_837'].append(file.count('~ST*837'))\n",
    "    log['Num_837p'].append(file.count('005010x22A1'))\n",
    "    log['Num_837i'].append(file.count('~ST*837') - file.count('005010x22A1'))\n",
    "    log['file_release'].append(dt_string)\n",
    "\n",
    "def claim_clean(file):\n",
    "    file = [w.replace('!','*') for w in file]\n",
    "    file = [w.replace('\\\\|',':') for w in file]\n",
    "    file = [w.replace('>',':') for w in file]\n",
    "    file = [w.replace('[\\r\\n]',' ') for w in file]\n",
    "    return file\n",
    "\n",
    "\n",
    "path = 'C:/Users/JacobMacKinnon/Documents/Data_Upload/Endeavor_New_data'\n",
    "path_master = 'C:/Users/JacobMacKinnon/Documents/Data_Upload/Endeavor_DMZ/Master/Endeaver_'\n",
    "path_process = 'C:/Users/JacobMacKinnon/Documents/Data_Upload/Endeavor_DMZ/Process/'\n",
    "if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "    os.chdir(path)\n",
    "    for files in os.listdir(path):\n",
    "        if files[-4:] == '.zip':\n",
    "            print('file is a zip')\n",
    "            zfile = z.ZipFile(files, 'r')\n",
    "            for item in zfile.namelist():\n",
    "                fa = zfile.read(item)\n",
    "                file = fa.decode(\"ascii\")\n",
    "                log_file(file, item)\n",
    "                if ('~ST*835' in file) and ('ISA*' in file):\n",
    "                    afile.append(file)\n",
    "                    #print( '835')\n",
    "                elif ('~ST*837' in file) and ('ISA*' in file) and ('005010X222A1' not in file):\n",
    "                    bifile.append(file)\n",
    "                    #print( '837')\n",
    "                elif ('~ST*837' in file) and ('ISA*' in file) and ('005010X222A1' in file):\n",
    "                    bpfile.append(file)\n",
    "                else:\n",
    "                    print('not a claim')\n",
    "                 \n",
    "                \n",
    "            #print(afile)\n",
    "            zfile.close()\n",
    "        else:\n",
    "            #print('file is not a zip')\n",
    "            f = open(files, 'r')\n",
    "            read_data = f.read()\n",
    "            log_file(read_data, f)\n",
    "            if ('~ST*835' in read_data) and ('ISA*' in read_data):\n",
    "                afile.append(read_data)\n",
    "            elif ('~ST*837' in read_data) and ('ISA*' in read_data) and ('005010X222A1' not in read_data):\n",
    "                bifile.append(read_data)\n",
    "            elif ('~ST*837' in read_data) and ('ISA*' in read_data) and ('005010X222A1' in read_data):\n",
    "                bpfile.append(read_data)\n",
    "            else:\n",
    "                print('not a claim')\n",
    "            f.close()\n",
    "            print('file is not a zip')\n",
    "\n",
    "\n",
    "    afile = claim_clean(afile)\n",
    "    bifile = claim_clean(bifile)\n",
    "    bpfile= claim_clean(bpfile)\n",
    "    \n",
    "    if len(afile) >= 1:\n",
    "        with open(path_master+dt_string+'_835', 'w') as new_file:\n",
    "            wr = csv.writer(new_file, quoting= csv.QUOTE_ALL)\n",
    "            wr.writerow(afile)\n",
    "            new_file.close()\n",
    "    else:\n",
    "        print('afile is empty')\n",
    "        \n",
    "\n",
    "    if len(bifile) >= 1:\n",
    "        with open(path_master+dt_string+'_837_i', 'w') as new_file_837_i:\n",
    "            wr = csv.writer(new_file_837_i, quoting= csv.QUOTE_ALL)\n",
    "            wr.writerow(bifile)\n",
    "            new_file_837_i.close()\n",
    "    else:\n",
    "        print('bifile is empty')\n",
    "\n",
    "\n",
    "    if len(bpfile) >= 1:\n",
    "        with open(path_master+dt_string+'_837_p', 'w') as new_file_837_p:\n",
    "            wr = csv.writer(new_file_837_p, quoting= csv.QUOTE_ALL)\n",
    "            wr.writerow(bpfile)\n",
    "            new_file_837_p.close()\n",
    "    else:\n",
    "        print('bpfile is empty')\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(log)\n",
    "    ##df.to_csv('C:\\\\Users\\\\JacobMacKinnon\\\\Documents\\\\Data_Upload\\\\Endeavor_log\\\\'+dt_string+'.csv')\n",
    "    df.to_csv('C:\\\\Users\\\\JacobMacKinnon\\\\Documents\\\\Data_Upload\\\\Endeavor_log\\\\Endeavor_log_files.csv', mode='a', header=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for folder in os.listdir(path):\n",
    "        ##os.chdir(path)\n",
    "        ##os.close(folder)\n",
    "        os.rename(folder, path_process+dt_string+folder )\n",
    "        ##os.chdir(path)\n",
    "        ##folder.close()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "else:\n",
    "    print('No Files')\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "import psycopg2\n",
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "engine = sq.create_engine('postgresql://jmackinnon:Password@10.136.53.69:5432/SOURCE_DATA',connect_args={'options':'-csearch_path=source_data'})\n",
    "##names = engine.table_names()\n",
    "\n",
    "\n",
    "with open(r'C:\\Users\\JacobMacKinnon\\Documents\\Data_Upload\\Endeavor_log\\Endeavor_log_files.csv', 'r') as file:\n",
    "    data_df = pd.read_csv(file)\n",
    "data_df.to_sql('data_upload_log_jm', con=engine, index=True, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysftp\n",
    "\n",
    "#Host Site\n",
    "host = 'ws_ftp.example.com'\n",
    "\n",
    "# Loads .ssh/known_hosts\n",
    "cnopts = pysftp.CnOpts()\n",
    "\n",
    "hostkeys = None\n",
    "\n",
    "#if cnopts.hostkeys.lookup(host) == None:\n",
    "    print(\"New host - will accept any host key\")\n",
    "    # Backup loaded .ssh/known_hosts file\n",
    "    hostkeys = cnopts.hostkeys\n",
    "    # And do not verify host key of the new host\n",
    "    cnopts.hostkeys = None\n",
    "\n",
    "with pysftp.Connection(host, username='user', password='password', cnopts=cnopts) as sftp:\n",
    "    if hostkeys != None:\n",
    "        print(\"Connected to new host, caching its hostkey\")\n",
    "        hostkeys.add(host, sftp.remote_server_key.get_name(), sftp.remote_server_key)\n",
    "        hostkeys.save(pysftp.helpers.known_hosts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y%m%d\")\n",
    "path_master = r'C:\\Users\\JacobMacKinnon\\Documents\\Data_Upload\\Endeavor_DMZ\\Master'\n",
    "\n",
    "hi_data = r'hi-data-upload-utility uploadDataSetFile'\n",
    "said = r'-said ba1cf4bb-2ee2-4c7e-ab50-91621835cf2a'\n",
    "sas = r'-sas jGNzAzwB6ePgiRX7kqINvwLXto2hi0Fn'\n",
    "sid = r'-sid b592d16e-9597-4b48-b582-64dde1d48144'\n",
    "dsid = r'-dsid' +files\n",
    "sv = r'-sv 1'\n",
    "fid = '-fid SINGLE_FILE'\n",
    "rl = '-rl' +dt_string\n",
    "f =\n",
    "\n",
    "for files in os.listdir(path_master):\n",
    "\n",
    "    os.chdir(r\"C:/Users/JacobMacKinnon/Desktop/hi-data-upload-utility-1.6/bin\")\n",
    "    string = r\"hi-data-upload-utility uploadDataSetFile -said ba1cf4bb-2ee2-4c7e-ab50-91621835cf2a \"\n",
    "    string1 = r\"-sas jGNzAzwB6ePgiRX7kqINvwLXto2hi0Fn -sid b592d16e-9597-4b48-b582-64dde1d48144 -dsid  \" + files\n",
    "    string2 = r\"-sv 1 -fid SINGLE_FILE -rl \" +dt_string+ r\"-f  C:\\\\Users\\\\JacobMacKinnon\\\\Documents\\\\Data_Upload\\\\Endeavor_DMZ\\\\Master\\\\\" +files\n",
    "    string4 = string + string1 + string2\n",
    "    #! $string4\n",
    "    print(string4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
